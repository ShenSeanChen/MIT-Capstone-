{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a linear function for f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "t = 300\n",
    "x = np.random.uniform(0,1, n)\n",
    "a = np.random.uniform(-1,1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39258359, 0.17741823, 0.59250329, 0.54281811, 0.33530203,\n",
       "       0.62242382, 0.31806745, 0.12839349, 0.88517413, 0.24545588])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22190737, -0.70470618, -0.28948519,  0.35585917,  0.44527886,\n",
       "       -0.74862312, -0.30095507, -0.87786712, -0.1669726 , -0.95652113])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9239426147152634"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_linear(x):   \n",
    "    return np.dot(a,x.T)\n",
    "\n",
    "f_linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation for Multi-Linear Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7980966155975172\n",
      "-0.99250439092805\n",
      "-0.9334419022178256\n"
     ]
    }
   ],
   "source": [
    "x_sample = 0\n",
    "\n",
    "def F_unfixed(x, f, t, x_sample): \n",
    "    # Here, take x_sample as a parameter for the ease of \n",
    "    # using both the F and F_fixed functions in this framework\n",
    "\n",
    "    sum_R = 0\n",
    "\n",
    "    for i in range(t):\n",
    "\n",
    "        x_sample = np.random.uniform(0,1, x.shape)\n",
    "\n",
    "        R_t = x >= x_sample\n",
    "\n",
    "        sum_R = sum_R + f(R_t)\n",
    "\n",
    "    return sum_R/t\n",
    "\n",
    "# In Function F, re-sample from x every time we run the function\n",
    "print(F_unfixed(x, f_linear, 100, x_sample))\n",
    "print(F_unfixed(x, f_linear, 100, x_sample))\n",
    "print(F_unfixed(x, f_linear, 100, x_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from x (stored in x_sample) once and for all  \n",
    "# x_sample defined here will be used as a parameter for the code below\n",
    "\n",
    "def get_x_sample(t): \n",
    "    x_sample = []\n",
    "    for i in range(t):\n",
    "        x_sample.append(np.random.uniform(0,1, x.shape))\n",
    "        \n",
    "    return x_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0633340141700303\n",
      "-1.0633340141700303\n",
      "-1.0633340141700303\n"
     ]
    }
   ],
   "source": [
    "x_sample = get_x_sample(t)\n",
    "\n",
    "def F_fixed(x, f, t, x_sample):\n",
    "    # Here, we do not re-sample from x every time we run the function\n",
    "    # Instead, we take a collection of x samples and compute the estimated expectation\n",
    "    \n",
    "    sum_R = 0\n",
    "    for i in range(t):\n",
    "        R_t = x >= x_sample[i]\n",
    "        sum_R = sum_R + f(R_t)\n",
    "    return sum_R/t\n",
    "                 \n",
    "print(F_fixed(x, f_linear, 100, x_sample))\n",
    "print(F_fixed(x, f_linear, 100, x_sample))\n",
    "print(F_fixed(x, f_linear, 100, x_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.73569541  0.62903284  0.26188165  0.63377371  0.44822793  0.70714339\n",
      " -0.16722055 -0.33568168 -0.29152329  0.56592234]\n"
     ]
    }
   ],
   "source": [
    "def get_gradient_F(F,x,f,t,n,x_sample):\n",
    "    # A vectorized function to get gradients\n",
    "    \n",
    "    x_new_1 = x*np.ones((n, n))\n",
    "    x_new_0 = x*np.ones((n, n))\n",
    "\n",
    "    np.fill_diagonal(x_new_1, 1)\n",
    "    np.fill_diagonal(x_new_0, 0)\n",
    "    \n",
    "    return F(x_new_1, f, t, x_sample) - F(x_new_0, f, t, x_sample)\n",
    "\n",
    "print(get_gradient_F(F_fixed,x,f_linear,t,n,x_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ascent(F, x, f, alpha, t, epsilon, n, n_step_max, grad_decay = False, input_x_sample = None):  \n",
    "    \n",
    "    if input_x_sample == None:\n",
    "        x_sample = get_x_sample(t)\n",
    "    else:\n",
    "        x_sample = input_x_sample\n",
    "    \n",
    "    x = copy.deepcopy(x)\n",
    "    x_init = copy.deepcopy(x)\n",
    "    sum_init = F(x, f, t, x_sample)\n",
    "    \n",
    "    # key values to be used\n",
    "    sum_update = 0\n",
    "    step = 0\n",
    "    \n",
    "    sum_temp = copy.deepcopy(sum_init)\n",
    "    \n",
    "    # start updating the parameters x with iterative gradients\n",
    "#     while (np.abs(sum_temp - sum_update) > epsilon) & (step < n_step_max) :    \n",
    "    while  (step < n_step_max) :  \n",
    "#     while (np.abs(sum_temp - sum_update) > epsilon) & (sum_update > sum_temp) & (step < n_step_max) :\n",
    "  \n",
    "        step += 1\n",
    "        sum_temp = F(x, f, t, x_sample)\n",
    "        x_temp = x\n",
    "        \n",
    "        grad = get_gradient_F(F,x,f,t,n, x_sample)\n",
    "        \n",
    "        x = x + alpha*grad\n",
    "        x = np.maximum(np.minimum(x,1),0)\n",
    "        \n",
    "        sum_update = F(x, f, t, x_sample)\n",
    "        \n",
    "        if grad_decay == True:\n",
    "            alpha *= (1/step)**(1/5)\n",
    "            print(\"alpha: \", alpha, '\\n')\n",
    "        \n",
    "    print(\"\\n\",\n",
    "          \"Iteration: \", step, \"\\n\\n\" , \n",
    "          \"Gradient:  \", grad, \"\\n\\n\",\n",
    "          \"x updated: \", x, \"\\n\",\n",
    "          \"Updated  value: \", sum_update,\"\\n\\n\", \n",
    "          \"x second last: \", x_temp, \"\\n\",\n",
    "          \"Second last value: \", sum_temp, \"\\n\\n\")\n",
    "    \n",
    "        \n",
    "    \n",
    "    return step,sum_update, x, x_temp, x_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with a linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00337801 0.43522002 0.06116302 0.9202457  0.7709123  0.76154319\n",
      " 0.29273609 0.57126824 0.98487723 0.09116732]\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# parameters\n",
    "###\n",
    "\n",
    "# coefficients for the linear function\n",
    "a = np.random.uniform(-1,1, n)\n",
    "\n",
    "# parameters fo the gradient ascent function\n",
    "alpha = 0.01\n",
    "epsilon = 10**(-5000)\n",
    "n_step_max = 5000\n",
    "\n",
    "# number of iterations for estimating the expectation\n",
    "t = 300\n",
    "\n",
    "# number of products in the assortment\n",
    "n = 10\n",
    "\n",
    "# initialize the x vector\n",
    "x_initial = np.random.uniform(0,1, n)\n",
    "print(x_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for different values of a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11554293  0.21332587  0.07376636 -0.71596824 -0.6905506   0.25964938\n",
      "  0.35542768 -0.93685592  0.12339781 -0.1078814 ]\n",
      "\n",
      " Iteration:  5000 \n",
      "\n",
      " Gradient:   [ 0.11554293  0.21332587  0.07376636 -0.71596824 -0.6905506   0.25964938\n",
      "  0.35542768 -0.93685592  0.12339781 -0.1078814 ] \n",
      "\n",
      " x updated:  [1. 1. 1. 0. 0. 1. 1. 0. 1. 0.] \n",
      " Updated  value:  1.1411100383653545 \n",
      "\n",
      " x second last:  [1. 1. 1. 0. 0. 1. 1. 0. 1. 0.] \n",
      " Second last value:  1.1411100383653545 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Â Use function F_fixed: sampling for estimating expectation is only done once and for all\n",
    "print(a)\n",
    "# x_initial = np.random.uniform(0,1,n)\n",
    "step_,sum_update_, x_, x_temp_, x_sample_ = gradient_ascent(F_fixed, x_initial, f_linear, alpha, t, epsilon, n, \n",
    "                                                            n_step_max, grad_decay=False, input_x_sample = x_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that the last two iterations actually converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (2nd last iter):  [0.1256412  1.         0.63814269 1.         0.38902341 0.21389091\n",
      " 1.         0.         1.         1.        ]\n",
      "Value of F (2nd last iter):  2.551763805394968 \n",
      "\n",
      "x (last iter):  [0.12048984 1.         0.6354695  1.         0.38639506 0.21471746\n",
      " 1.         0.         1.         1.        ]\n",
      "Value of F (last iter):  2.551763805394968\n"
     ]
    }
   ],
   "source": [
    "x_previous = x_temp_\n",
    "print(\"x (2nd last iter): \", x_previous)\n",
    "print(\"Value of F (2nd last iter): \", F_fixed(x_previous, f_linear, t, x_sample_), \"\\n\")\n",
    "\n",
    "x_updated  = x_\n",
    "print(\"x (last iter): \", x_updated)\n",
    "print(\"Value of F (last iter): \", F_fixed(x_updated, f_linear, t, x_sample_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we manually converge probs to 0 or 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.         0.63814269 1.         0.38902341 0.21389091\n",
      " 1.         0.         1.         1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.601560301488282"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_previous_modified = copy.deepcopy(x_previous)\n",
    "x_previous_modified[0] = 0\n",
    "x_previous_modified[6] = 1\n",
    "\n",
    "print(x_previous_modified)\n",
    "F_fixed(x_previous_modified, f_linear, t, x_sample_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The convergence will be actually much faster if we use decaying gradient here\n",
    "Due to the fact that there is no local maximum in the linear function.\n",
    "And that decreasing in steps will make the incremental change really small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.01 \n",
      "\n",
      "alpha:  0.008705505632961241 \n",
      "\n",
      "alpha:  0.0069882711877157925 \n",
      "\n",
      "alpha:  0.005296119205244061 \n",
      "\n",
      "alpha:  0.0038385194963737744 \n",
      "\n",
      "alpha:  0.0026824615199994182 \n",
      "\n",
      "alpha:  0.0018176652007284484 \n",
      "\n",
      "alpha:  0.0011992118057488942 \n",
      "\n",
      "alpha:  0.000772764910314653 \n",
      "\n",
      "alpha:  0.0004875816957196081 \n",
      "\n",
      "alpha:  0.000301834484571944 \n",
      "\n",
      "alpha:  0.00018362533756728568 \n",
      "\n",
      "alpha:  0.00010993701395130539 \n",
      "\n",
      "\n",
      " Iteration:  13 \n",
      "\n",
      " Gradient:   [-0.51513617  0.85715328 -0.2673194   0.77575729 -0.26283486  0.08265449\n",
      "  0.60366306 -0.94742592  0.52404917  0.09832171] \n",
      "\n",
      " x updated:  [0.17152594 0.04480645 0.48227552 0.72706698 0.06837715 1.\n",
      " 0.41338185 0.95047467 0.02739392 0.93411723] \n",
      " Updated  value:  -0.07578491974910434 \n",
      "\n",
      " x second last:  [0.17162053 0.04464906 0.48232461 0.72692453 0.06842541 1.\n",
      " 0.413271   0.95064865 0.02729769 0.93409917] \n",
      " Second last value:  -0.07578491974910434 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step_,sum_update_, x_, x_temp_, x_sample_  = gradient_ascent(F_fixed, x, f_linear, \n",
    "                                                             alpha, t, epsilon, n, n_step_max, \n",
    "                                                             grad_decay=True, input_x_sample=x_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization on x matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration:  131 \n",
      "\n",
      " Gradient:   [-0.51513617  0.85715328 -0.2673194   0.77575729 -0.26283486  0.08265449\n",
      "  0.60366306 -0.94742592  0.52404917  0.09832171] \n",
      "\n",
      " x updated:  [0.         1.         0.34993259 1.         0.         1.\n",
      " 1.         0.         1.         0.18470637] \n",
      " Updated  value:  2.763326688867575 \n",
      "\n",
      " x second last:  [0.         1.         0.35260578 1.         0.         1.\n",
      " 1.         0.         1.         0.18372315] \n",
      " Second last value:  2.763326688867575 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_initial = np.random.uniform(0,1,n)\n",
    "step_,sum_update_, x_, x_temp_, x_sample_ = gradient_ascent(F_fixed, x_initial, f_linear, alpha, t, epsilon, n, \n",
    "                                                            n_step_max,grad_decay=False, input_x_sample = x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration:  157 \n",
      "\n",
      " Gradient:   [-0.51513617  0.85715328 -0.2673194   0.77575729 -0.26283486  0.08265449\n",
      "  0.60366306 -0.94742592  0.52404917  0.09832171] \n",
      "\n",
      " x updated:  [0.         1.         0.28371171 1.         0.         0.31779926\n",
      " 1.         0.         1.         0.47334486] \n",
      " Updated  value:  2.7536242510370426 \n",
      "\n",
      " x second last:  [0.         1.         0.28638491 1.         0.         0.31697271\n",
      " 1.         0.         1.         0.47236164] \n",
      " Second last value:  2.7536242510370426 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_initial = np.random.uniform(0,1,n)\n",
    "step_,sum_update_, x_, x_temp_, x_sample_ = gradient_ascent(F_fixed, x_initial, f_linear, alpha, t, epsilon, n, \n",
    "                                                            n_step_max,grad_decay=False, input_x_sample = x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Iteration:  535 \n",
      "\n",
      " Gradient:   [-0.51906903  0.85084523 -0.26919578  0.77708264 -0.26767529  0.0852764\n",
      "  0.60822797 -0.94978136  0.51667688  0.09556656] \n",
      "\n",
      " x updated:  [0.         1.         0.         1.         0.         0.63707937\n",
      " 1.         0.         1.         0.84470702] \n",
      " Updated  value:  2.898524920965915 \n",
      "\n",
      " x second last:  [0.         1.         0.         1.         0.         0.63622661\n",
      " 1.         0.         1.         0.84375136] \n",
      " Second last value:  2.8985249209659183 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use function F: re-sampling is enabled in each iteration\n",
    "\n",
    "# Note: in this case, the value of the function could decrease as each time the estimated value of F is different \n",
    "#       due to differnt samples from x\n",
    "step_,sum_update_, x_, x_temp_, x_sample_  = gradient_ascent(F_unfixed, x_initial, f_linear, alpha, t, epsilon,\n",
    "                                                             n, n_step_max, grad_decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
