{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-linear approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(x, f, t):\n",
    "\n",
    "    sum_R = 0\n",
    "\n",
    "    for i in range(t):\n",
    "\n",
    "        x_bar = np.random.uniform(0,1, x.shape)\n",
    "\n",
    "        R_t = x >= x_bar\n",
    "\n",
    "        sum_R = sum_R + f(R_t)\n",
    "\n",
    "    return sum_R/t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_F(F,x,f,t,n):\n",
    "    \n",
    "    x_new_1 = x*np.ones((n, n))\n",
    "    x_new_0 = x*np.ones((n, n))\n",
    "\n",
    "    np.fill_diagonal(x_new_1, 1)\n",
    "    np.fill_diagonal(x_new_0, 0)\n",
    "    \n",
    "    return F(x_new_1, f, t) - F(x_new_0, f, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -0.77777778 -0.55555556 -0.33333333 -0.11111111  0.11111111\n",
      "   0.33333333  0.55555556  0.77777778  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "a = np.linspace(-1, 1, n).reshape(1,n)\n",
    "\n",
    "def f_linear(x):\n",
    "        \n",
    "    return np.dot(a,x.T)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to find maximum of $z^T \\times grad(x_t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_argmax(grad,n):\n",
    "    c = -1*grad.reshape(n,1)\n",
    "    b = np.zeros((n,2))\n",
    "    b[:,1] = 1\n",
    "    res = linprog(c, bounds = b)\n",
    "    return res.x.reshape(1,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_size_function(j):\n",
    "    return 2/(j+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frank-Wolfe algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Direction-finding subproblem: Find $z_j$ solving\n",
    "\n",
    "$ Maximize \\hspace{1em} z^T \\nabla f(x_j)$\n",
    "\n",
    "Step 2: Step size determination\n",
    "\n",
    "$ \\gamma = \\frac{2}{2+j}$\n",
    "\n",
    "Step 3: Update\n",
    "\n",
    "$ x_j = \\gamma \\times z_j + (1-\\gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FW(F,gradient_F,f,t,n,max_iter,step_size,x_initial):\n",
    "    \n",
    "    x_j = x_initial\n",
    "    \n",
    "    for j in range(1,max_iter+1):\n",
    "        \n",
    "        grad = gradient_F(F,x_j,f,t,n)\n",
    "        \n",
    "        z_j = get_argmax(grad,n)\n",
    "        \n",
    "        gamma = step_size(j)\n",
    "        \n",
    "        x_j = gamma*z_j + (1-gamma)*x_j\n",
    "        \n",
    "        print(\"iter: \",j,\"\\n\",\"x: \", x_j,\"\\n\", \"z: \",z_j,\"\\n\", \"gradient: \",grad,\"\\n\", \"gamma: \",gamma,\"\\n\")\n",
    "    \n",
    "    return z_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "t = 150\n",
    "max_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26579092 0.49473829 0.64252405 0.56083454 0.9580608  0.1139196\n",
      "  0.57495446 0.55132709 0.09001225 0.33089829]]\n"
     ]
    }
   ],
   "source": [
    "x_initial = np.random.uniform(0,1, (1,n))\n",
    "print(x_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:  1 \n",
      " x:  [[0.08859697 0.16491276 0.21417468 0.18694485 0.3193536  0.70463987\n",
      "  0.85831815 0.85044236 0.69667075 0.7769661 ]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-0.9962963  -0.79703704 -0.58592593 -0.29185185 -0.14296296  0.21703704\n",
      "   0.35777778  0.59111111  0.68888889  1.11037037]] \n",
      " gamma:  0.6666666666666666 \n",
      "\n",
      "iter:  2 \n",
      " x:  [[0.04429849 0.08245638 0.10708734 0.09347242 0.1596768  0.85231993\n",
      "  0.92915908 0.92522118 0.84833537 0.88848305]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-0.85703704 -0.78814815 -0.5962963  -0.38518519 -0.08444444  0.10740741\n",
      "   0.17925926  0.61555556  0.82        0.91407407]] \n",
      " gamma:  0.5 \n",
      "\n",
      "iter:  3 \n",
      " x:  [[0.02657909 0.04947383 0.0642524  0.05608345 0.09580608 0.91139196\n",
      "  0.95749545 0.95513271 0.90900122 0.93308983]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-1.05481481 -0.86444444 -0.54074074 -0.31259259 -0.20814815  0.05777778\n",
      "   0.41259259  0.46888889  0.84222222  0.96740741]] \n",
      " gamma:  0.4 \n",
      "\n",
      "iter:  4 \n",
      " x:  [[0.01771939 0.03298255 0.04283494 0.03738897 0.06387072 0.94092797\n",
      "  0.97166363 0.97008847 0.93933415 0.95539322]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-1.04518519 -0.74888889 -0.56444444 -0.32296296 -0.18        0.16666667\n",
      "   0.39407407  0.53555556  0.80148148  1.03111111]] \n",
      " gamma:  0.3333333333333333 \n",
      "\n",
      "iter:  5 \n",
      " x:  [[0.01265671 0.02355897 0.03059638 0.02670641 0.04562194 0.9578057\n",
      "  0.97975974 0.97863462 0.95666725 0.96813801]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-0.94296296 -0.72074074 -0.46592593 -0.38222222 -0.09703704  0.05481481\n",
      "   0.33333333  0.58962963  0.72814815  0.9762963 ]] \n",
      " gamma:  0.2857142857142857 \n",
      "\n",
      "iter:  6 \n",
      " x:  [[0.00949253 0.01766922 0.02294729 0.02002981 0.03421646 0.96835427\n",
      "  0.9848198  0.98397597 0.96750044 0.97610351]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-0.98740741 -0.81925926 -0.54074074 -0.36518519 -0.12222222  0.08074074\n",
      "   0.34        0.5162963   0.77703704  1.04518519]] \n",
      " gamma:  0.25 \n",
      "\n",
      "iter:  7 \n",
      " x:  [[0.00738308 0.01374273 0.01784789 0.01557874 0.0266128  0.97538666\n",
      "  0.98819318 0.98753686 0.97472256 0.98141384]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-0.98296296 -0.81185185 -0.58074074 -0.35185185 -0.11555556  0.10444444\n",
      "   0.36888889  0.55703704  0.74962963  1.02074074]] \n",
      " gamma:  0.2222222222222222 \n",
      "\n",
      "iter:  8 \n",
      " x:  [[0.00590646 0.01099418 0.01427831 0.01246299 0.02129024 0.98030932\n",
      "  0.99055454 0.99002949 0.97977805 0.98513107]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-0.97111111 -0.74666667 -0.54814815 -0.4037037  -0.15185185  0.08148148\n",
      "   0.35333333  0.49851852  0.74888889  1.0362963 ]] \n",
      " gamma:  0.2 \n",
      "\n",
      "iter:  9 \n",
      " x:  [[0.00483256 0.00899524 0.01168226 0.01019699 0.01741929 0.98388945\n",
      "  0.9922719  0.99184231 0.98345477 0.98783451]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-1.00740741 -0.77037037 -0.55851852 -0.3237037  -0.11185185  0.1037037\n",
      "   0.36740741  0.54814815  0.78148148  0.99185185]] \n",
      " gamma:  0.18181818181818182 \n",
      "\n",
      "iter:  10 \n",
      " x:  [[0.00402714 0.00749603 0.00973521 0.00849749 0.01451607 0.98657454\n",
      "  0.99355992 0.99320193 0.98621231 0.9898621 ]] \n",
      " z:  [[0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]] \n",
      " gradient:  [[-1.00074074 -0.76074074 -0.54592593 -0.33703704 -0.11111111  0.11333333\n",
      "   0.2962963   0.52814815  0.80888889  1.01851852]] \n",
      " gamma:  0.16666666666666666 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FW(F,get_gradient_F,f_linear,t,n,max_iter,step_size_function,x_initial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
